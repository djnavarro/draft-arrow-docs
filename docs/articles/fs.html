<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="arrow">
<title>Working with Cloud Storage (S3, GCS) • Arrow R Package</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.1.3/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.1.3/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><script src="../extra.js"></script><meta property="og:title" content="Working with Cloud Storage (S3, GCS)">
<meta property="og:description" content="arrow">
<meta property="og:image" content="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png">
<meta property="og:image:alt" content="Apache Arrow logo, displaying the triple chevron image adjacent to the text">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:creator" content="@apachearrow">
<meta name="twitter:site" content="@apachearrow">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Matomo --><script>
  var _paq = window._paq = window._paq || [];
  /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
  /* We explicitly disable cookie tracking to avoid privacy issues */
  _paq.push(['disableCookies']);
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u="https://analytics.apache.org/";
    _paq.push(['setTrackerUrl', u+'matomo.php']);
    _paq.push(['setSiteId', '20']);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
  })();
</script><!-- End Matomo Code -->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-black"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">Arrow R Package</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">9.0.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="external-link nav-link" href="https://arrow.apache.org/">❯❯❯</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../articles/arrow.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <h6 class="dropdown-header" data-toc-skip>Data anaysis tasks</h6>
    <a class="dropdown-item" href="../articles/read_write.html">Reading and writing data files</a>
    <a class="dropdown-item" href="../articles/data_wrangling.html">Using dplyr with arrow</a>
    <a class="dropdown-item" href="../articles/data_types.html">Data types in Arrow and R</a>
    <a class="dropdown-item" href="../articles/dataset.html">Working with Arrow Datasets and dplyr</a>
    <a class="dropdown-item" href="../articles/fs.html">Working with Cloud Storage (S3, GCS)</a>
    <a class="dropdown-item" href="../articles/python.html">Apache Arrow in Python and R with reticulate</a>
    <a class="dropdown-item" href="../articles/flight.html">Connecting to Arrow Flight Servers</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Contributing to Arrow</h6>
    <a class="dropdown-item" href="../articles/developer_guide.html">Arrow Developer Guide</a>
    <a class="dropdown-item" href="../articles/developer_environment.html">Arrow Developer Environment</a>
    <a class="dropdown-item" href="../articles/developer_workflow.html">Arrow Developer Workflow</a>
    <a class="dropdown-item" href="../articles/debugging.html">Debugging Arrow</a>
    <a class="dropdown-item" href="../articles/docker.html">Using Docker with Arrow</a>
    <a class="dropdown-item" href="../articles/bindings.html">Writing Arrow Bindings</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Installation topics</h6>
    <a class="dropdown-item" href="../articles/install_linux.html">Installing Arrow on Linux</a>
    <a class="dropdown-item" href="../articles/install_nightly.html">Installing development versions</a>
    <a class="dropdown-item" href="../articles/install_details.html">Understanding Arrow installation</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-project-docs">Project docs</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-project-docs">
    <a class="external-link dropdown-item" href="https://arrow.apache.org/docs/format/Columnar.html">Specification</a>
    <a class="external-link dropdown-item" href="https://arrow.apache.org/docs/c_glib">C GLib</a>
    <a class="external-link dropdown-item" href="https://arrow.apache.org/docs/cpp">C++</a>
    <a class="external-link dropdown-item" href="https://arrow.apache.org/docs/java">Java</a>
    <a class="external-link dropdown-item" href="https://arrow.apache.org/docs/js">JavaScript</a>
    <a class="external-link dropdown-item" href="https://arrow.apache.org/docs/python">Python</a>
    <a class="dropdown-item" href="../index.html">R</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Working with Cloud Storage (S3, GCS)</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/apache/arrow/blob/master/r/vignettes/fs.Rmd" class="external-link"><code>vignettes/fs.Rmd</code></a></small>
      <div class="d-none name"><code>fs.Rmd</code></div>
    </div>

    
    
<p>The Arrow C++ library includes a generic filesystem interface and
specific implementations for some cloud storage systems. This setup
allows various parts of the project to be able to read and write data
with different storage backends. In the <code>arrow</code> R package,
support has been enabled for AWS S3 and Google Cloud Storage (GCS). This
vignette provides an overview of working with S3 and GCS data using
Arrow.</p>
<blockquote>
<p>In Windows and macOS binary packages, S3 and GCS support are
included. On Linux when installing from source, S3 and GCS support is
not always enabled by default, and it has additional system
requirements. See <code><a href="https://arrow.apache.org/docs/r/articles/install.html">vignette("install", package = "arrow")</a></code>
for details.</p>
</blockquote>
<div class="section level2">
<h2 id="creating-a-filesystem-object">Creating a FileSystem object<a class="anchor" aria-label="anchor" href="#creating-a-filesystem-object"></a>
</h2>
<p>One way of working with filesystems is to create
<code><a href="../reference/FileSystem.html">?FileSystem</a></code> objects. <code><a href="../reference/FileSystem.html">?S3FileSystem</a></code> objects can
be created with the <code><a href="../reference/s3_bucket.html">s3_bucket()</a></code> function, which
automatically detects the bucket’s AWS region. Similarly,
<code><a href="../reference/FileSystem.html">?GcsFileSystem</a></code> objects can be created with the
<code><a href="../reference/gs_bucket.html">gs_bucket()</a></code> function. The resulting <code>FileSystem</code>
will consider paths relative to the bucket’s path (so for example you
don’t need to prefix the bucket path when listing a directory).</p>
<p>With a <code>FileSystem</code> object, you can point to specific
files in it with the <code>$path()</code> method and pass the result to
file readers and writers (<code><a href="../reference/read_parquet.html">read_parquet()</a></code>,
<code><a href="../reference/write_feather.html">write_feather()</a></code>, et al.). For example, to read a parquet
file from the example NYC taxi data (used in
<code><a href="../articles/dataset.html">vignette("dataset", package = "arrow")</a></code>):</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">bucket</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/s3_bucket.html">s3_bucket</a></span><span class="op">(</span><span class="st">"voltrondata-labs-datasets"</span><span class="op">)</span>
<span class="co"># Or in GCS (anonymous = TRUE is required if credentials are not configured):</span>
<span class="va">bucket</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/gs_bucket.html">gs_bucket</a></span><span class="op">(</span><span class="st">"voltrondata-labs-datasets"</span>, anonymous <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/read_parquet.html">read_parquet</a></span><span class="op">(</span><span class="va">bucket</span><span class="op">$</span><span class="fu">path</span><span class="op">(</span><span class="st">"nyc-taxi/year=2019/month=6/part-0.parquet"</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>Note that this will be slower to read than if the file were local,
though if you’re running on a machine in the same AWS region as the file
in S3, the cost of reading the data over the network should be much
lower.</p>
<p>You can list the files and/or directories in a bucket or subdirectory
using the <code>$ls()</code> method:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">bucket</span><span class="op">$</span><span class="fu">ls</span><span class="op">(</span><span class="st">"nyc-taxi"</span><span class="op">)</span>
<span class="co"># Or recursive:</span>
<span class="va">bucket</span><span class="op">$</span><span class="fu">ls</span><span class="op">(</span><span class="st">"nyc-taxi"</span>, recursive <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<p><strong>NOTE</strong>: in GCS, you <em>should always</em> use
<code>recursive = TRUE</code> as directories often don’t appear in
<code>$ls()</code> results.</p>
<!-- TODO: update GCS note above if ARROW-17097 is addressed -->
<p>See <code><a href="../reference/FileSystem.html">help(FileSystem)</a></code> for a list of options that
<code><a href="../reference/s3_bucket.html">s3_bucket()</a></code>/<code>S3FileSystem$create()</code> and
<code><a href="../reference/gs_bucket.html">gs_bucket()</a></code>/<code>GcsFileSystem$create()</code> can
take.</p>
<p>The object that <code><a href="../reference/s3_bucket.html">s3_bucket()</a></code> and <code><a href="../reference/gs_bucket.html">gs_bucket()</a></code>
return is technically a <code>SubTreeFileSystem</code>, which holds a
path and a file system to which it corresponds.
<code>SubTreeFileSystem</code>s can be useful for holding a reference to
a subdirectory somewhere (on S3, GCS, or elsewhere).</p>
<p>One way to get a subtree is to call the <code>$cd()</code> method on
a <code>FileSystem</code></p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">june2019</span> <span class="op">&lt;-</span> <span class="va">bucket</span><span class="op">$</span><span class="fu">cd</span><span class="op">(</span><span class="st">"nyc-taxi/year=2019/month=6"</span><span class="op">)</span>
<span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/read_parquet.html">read_parquet</a></span><span class="op">(</span><span class="va">june2019</span><span class="op">$</span><span class="fu">path</span><span class="op">(</span><span class="st">"part-0.parquet"</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p><code>SubTreeFileSystem</code> can also be made from a URI:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">june2019</span> <span class="op">&lt;-</span> <span class="va">SubTreeFileSystem</span><span class="op">$</span><span class="fu">create</span><span class="op">(</span><span class="st">"s3://voltrondata-labs-datasets/nyc-taxi/year=2019/month=6"</span><span class="op">)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="uris">URIs<a class="anchor" aria-label="anchor" href="#uris"></a>
</h2>
<p>File readers and writers (<code><a href="../reference/read_parquet.html">read_parquet()</a></code>,
<code><a href="../reference/write_feather.html">write_feather()</a></code>, et al.) also accept a URI as the source or
destination file, as do <code><a href="../reference/open_dataset.html">open_dataset()</a></code> and
<code><a href="../reference/write_dataset.html">write_dataset()</a></code>. An S3 URI looks like:</p>
<pre><code>s3://[access_key:secret_key@]bucket/path[?region=]</code></pre>
<p>A GCS URI looks like:</p>
<pre><code>gs://[access_key:secret_key@]bucket/path
gs://anonymous@bucket/path</code></pre>
<p>For example, one of the NYC taxi data files used in
<code><a href="../articles/dataset.html">vignette("dataset", package = "arrow")</a></code> is found at</p>
<pre><code>s3://voltrondata-labs-datasets/nyc-taxi/year=2019/month=6/part-0.parquet
# Or in GCS (anonymous required on public buckets):
gs://anonymous@voltrondata-labs-datasets/nyc-taxi/year=2019/month=6/part-0.parquet</code></pre>
<p>Given this URI, you can pass it to <code><a href="../reference/read_parquet.html">read_parquet()</a></code> just
as if it were a local file path:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/read_parquet.html">read_parquet</a></span><span class="op">(</span><span class="st">"s3://voltrondata-labs-datasets/nyc-taxi/year=2019/month=6/part-0.parquet"</span><span class="op">)</span>
<span class="co"># Or in GCS:</span>
<span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/read_parquet.html">read_parquet</a></span><span class="op">(</span><span class="st">"gs://anonymous@voltrondata-labs-datasets/nyc-taxi/year=2019/month=6/part-0.parquet"</span><span class="op">)</span></code></pre></div>
<div class="section level3">
<h3 id="uri-options">URI options<a class="anchor" aria-label="anchor" href="#uri-options"></a>
</h3>
<p>URIs accept additional options in the query parameters (the part
after the <code>?</code>) that are passed down to configure the
underlying file system. They are separated by <code>&amp;</code>. For
example,</p>
<pre><code>s3://voltrondata-labs-datasets/?endpoint_override=https%3A%2F%2Fstorage.googleapis.com&amp;allow_bucket_creation=true</code></pre>
<p>is equivlant to:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fs</span> <span class="op">&lt;-</span> <span class="va">S3FileSystem</span><span class="op">$</span><span class="fu">create</span><span class="op">(</span>
  endpoint_override<span class="op">=</span><span class="st">"https://storage.googleapis.com"</span>,
  allow_bucket_creation<span class="op">=</span><span class="cn">TRUE</span>
<span class="op">)</span>
<span class="va">fs</span><span class="op">$</span><span class="fu">path</span><span class="op">(</span><span class="st">"voltrondata-labs-datasets/"</span><span class="op">)</span></code></pre></div>
<p>Both tell the <code>S3FileSystem</code> that it should allow the
creation of new buckets and to talk to Google Storage instead of S3. The
latter works because GCS implements an S3-compatible API–see <a href="#file-systems-that-emulate-s3">File systems that emulate S3</a>
below–but for better support for GCS use the GCSFileSystem with
<code>gs://</code>. Also note that parameters in the URI need to be <a href="https://en.wikipedia.org/wiki/Percent-encoding" class="external-link">percent
encoded</a>, which is why <code>://</code> is written as
<code>%3A%2F%2F</code>.</p>
<p>For S3, only the following options can be included in the URI as
query parameters are <code>region</code>, <code>scheme</code>,
<code>endpoint_override</code>, <code>access_key</code>,
<code>secret_key</code>, <code>allow_bucket_creation</code>, and
<code>allow_bucket_deletion</code>. For GCS, the supported parameters
are <code>scheme</code>, <code>endpoint_override</code>, and
<code>retry_limit_seconds</code>.</p>
<p>In GCS, a useful option is <code>retry_limit_seconds</code>, which
sets the number of seconds a request may spend retrying before returning
an error. The current default is 15 minutes, so in many interactive
contexts it’s nice to set a lower value:</p>
<pre><code>gs://anonymous@voltrondata-labs-datasets/nyc-taxi/?retry_limit_seconds=10</code></pre>
</div>
</div>
<div class="section level2">
<h2 id="authentication">Authentication<a class="anchor" aria-label="anchor" href="#authentication"></a>
</h2>
<div class="section level3">
<h3 id="s3-authentication">S3 Authentication<a class="anchor" aria-label="anchor" href="#s3-authentication"></a>
</h3>
<p>To access private S3 buckets, you need typically need two secret
parameters: a <code>access_key</code>, which is like a user id, and
<code>secret_key</code>, which is like a token or password. There are a
few options for passing these credentials:</p>
<ul>
<li><p>Include them in the URI, like
<code>s3://access_key:secret_key@bucket-name/path/to/file</code>. Be
sure to <a href="https://en.wikipedia.org/wiki/Percent-encoding" class="external-link">URL-encode</a>
your secrets if they contain special characters like “/” (e.g.,
<code>URLencode("123/456", reserved = TRUE)</code>).</p></li>
<li><p>Pass them as <code>access_key</code> and <code>secret_key</code>
to <code>S3FileSystem$create()</code> or
<code><a href="../reference/s3_bucket.html">s3_bucket()</a></code></p></li>
<li><p>Set them as environment variables named
<code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code>,
respectively.</p></li>
<li><p>Define them in a <code>~/.aws/credentials</code> file, according
to the <a href="https://docs.aws.amazon.com/sdk-for-cpp/v1/developer-guide/credentials.html" class="external-link">AWS
documentation</a>.</p></li>
<li><p>Use an <a href="https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html" class="external-link">AccessRole</a>
for temporary access by passing the <code>role_arn</code> identifier to
<code>S3FileSystem$create()</code> or <code><a href="../reference/s3_bucket.html">s3_bucket()</a></code>.</p></li>
</ul>
</div>
<div class="section level3">
<h3 id="gcs-authentication">GCS Authentication<a class="anchor" aria-label="anchor" href="#gcs-authentication"></a>
</h3>
<p>The simplest way to authenticate with GCS is to run the <a href="https://cloud.google.com/sdk/docs/" class="external-link">gcloud</a> command to setup
application default credentials:</p>
<pre><code>gcloud auth application-default login</code></pre>
<p>To manually configure credentials, you can pass either
<code>access_token</code> and <code>expiration</code>, for using
temporary tokens generated elsewhere, or <code>json_credentials</code>,
to reference a downloaded credentials file.</p>
<p>If you haven’t configured credentials, then to access <em>public</em>
buckets, you must pass <code>anonymous = TRUE</code> or
<code>anonymous</code> as the user in a URI:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">bucket</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/gs_bucket.html">gs_bucket</a></span><span class="op">(</span><span class="st">"voltrondata-labs-datasets"</span>, anonymous <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="va">fs</span> <span class="op">&lt;-</span> <span class="va">GcsFileSystem</span><span class="op">$</span><span class="fu">create</span><span class="op">(</span>anonymous <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/read_parquet.html">read_parquet</a></span><span class="op">(</span><span class="st">"gs://anonymous@voltrondata-labs-datasets/nyc-taxi/year=2019/month=6/part-0.parquet"</span><span class="op">)</span></code></pre></div>
<!-- TODO(ARROW-16880): Describe what credentials to use for particular use cases
and how to integrate with gargle library. -->
</div>
</div>
<div class="section level2">
<h2 id="using-a-proxy-server">Using a proxy server<a class="anchor" aria-label="anchor" href="#using-a-proxy-server"></a>
</h2>
<p>If you need to use a proxy server to connect to an S3 bucket, you can
provide a URI in the form <code>http://user:password@host:port</code> to
<code>proxy_options</code>. For example, a local proxy server running on
port 1316 can be used like this:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">bucket</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/s3_bucket.html">s3_bucket</a></span><span class="op">(</span><span class="st">"voltrondata-labs-datasets"</span>, proxy_options <span class="op">=</span> <span class="st">"http://localhost:1316"</span><span class="op">)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="file-systems-that-emulate-s3">File systems that emulate S3<a class="anchor" aria-label="anchor" href="#file-systems-that-emulate-s3"></a>
</h2>
<p>The <code>S3FileSystem</code> machinery enables you to work with any
file system that provides an S3-compatible interface. For example, <a href="https://min.io/" class="external-link">MinIO</a> is and object-storage server that
emulates the S3 API. If you were to run <code>minio server</code>
locally with its default settings, you could connect to it with
<code>arrow</code> using <code>S3FileSystem</code> like this:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">minio</span> <span class="op">&lt;-</span> <span class="va">S3FileSystem</span><span class="op">$</span><span class="fu">create</span><span class="op">(</span>
  access_key <span class="op">=</span> <span class="st">"minioadmin"</span>,
  secret_key <span class="op">=</span> <span class="st">"minioadmin"</span>,
  scheme <span class="op">=</span> <span class="st">"http"</span>,
  endpoint_override <span class="op">=</span> <span class="st">"localhost:9000"</span>
<span class="op">)</span></code></pre></div>
<p>or, as a URI, it would be</p>
<pre><code>s3://minioadmin:minioadmin@?scheme=http&amp;endpoint_override=localhost%3A9000</code></pre>
<p>(note the URL escaping of the <code>:</code> in
<code>endpoint_override</code>).</p>
<p>Among other applications, this can be useful for testing out code
locally before running on a remote S3 bucket.</p>
</div>
<div class="section level2">
<h2 id="disabling-the-use-of-environment-variables">Disabling the use of environment variables<a class="anchor" aria-label="anchor" href="#disabling-the-use-of-environment-variables"></a>
</h2>
<p>As mentioned above, it is possible to make use of environment
variables to configure access. However, if you wish to pass in
connection details via a URI or alternative methods but also have
existing AWS environment variables defined, these may interfere with
your session. For example, you may see an error message like:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>Error<span class="sc">:</span> IOError<span class="sc">:</span> When resolving region <span class="cf">for</span> bucket <span class="st">'analysis'</span><span class="sc">:</span> AWS Error [code <span class="dv">99</span>]<span class="sc">:</span> curlCode<span class="sc">:</span> <span class="dv">6</span>, Couldn<span class="st">'t resolve host name </span></span></code></pre></div>
<p>You can unset these environment variables using
<code><a href="https://rdrr.io/r/base/Sys.setenv.html" class="external-link">Sys.unsetenv()</a></code>, for example:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Sys.setenv.html" class="external-link">Sys.unsetenv</a></span><span class="op">(</span><span class="st">"AWS_DEFAULT_REGION"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/Sys.setenv.html" class="external-link">Sys.unsetenv</a></span><span class="op">(</span><span class="st">"AWS_S3_ENDPOINT"</span><span class="op">)</span></code></pre></div>
<p>By default, the AWS SDK tries to retrieve metadata about user
configuration, which can cause conficts when passing in connection
details via URI (for example when accessing a MINIO bucket). To disable
the use of AWS environment variables, you can set environment variable
<code>AWS_EC2_METADATA_DISABLED</code> to <code>TRUE</code>.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Sys.setenv.html" class="external-link">Sys.setenv</a></span><span class="op">(</span>AWS_EC2_METADATA_DISABLED <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Neal Richardson, Ian Cook, Nic Crane, Dewey Dunnington, Romain François, Jonathan Keane, Dragoș Moldovan-Grünfeld, Jeroen Ooms, Apache Arrow.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.6.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
